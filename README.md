# ğŸ¾ PhoneClaw

**An open-source AI-powered phone automation agent for Android.**

PhoneClaw uses Android's Accessibility Service to give an AI agent full control over your phone â€” reading screens, tapping buttons, typing text, scrolling, navigating, and executing multi-step tasks through natural language commands.

> âš ï¸ **Early Development** â€” This project is under active development. Contributions welcome!

> [**Watch the Demo on Twitter**](https://twitter.com/8Dazo/status/2023592262782120054)

---

## âœ¨ Features

### Core Tools (Phase 1)
| Tool | Status | Description |
|------|--------|-------------|
| `scrollUp` / `scrollDown` | âœ… | Scroll with node detection + gesture fallback |
| `clickByText` | âœ… | Find and click elements by visible text |
| `getScreenText` | âœ… | Read all text on the current screen |
| `isServiceRunning` | âœ… | Check if accessibility service is active |
| `tap(x, y)` | ğŸ”œ | Tap at exact screen coordinates |
| `longPress(x, y)` | ğŸ”œ | Long press at coordinates |
| `swipe(x1, y1, x2, y2)` | ğŸ”œ | Arbitrary swipe gestures |
| `typeText(text)` | ğŸ”œ | Type into focused input fields |
| `pressBack` / `pressHome` | ğŸ”œ | System navigation actions |
| `getUITree` | ğŸ”œ | Full accessibility tree as structured JSON |
| `takeScreenshot` | âœ… | Capture screen for vision AI |

### Agent Integration (Phase 2)
- âœ… LLM-powered reasoning loop
- âœ… Natural language command interface
- âœ… Automatic tool selection and execution
- âœ… Chat UI with action visualization

### Advanced Features (Phase 3)
- âœ… App launcher by name
- âœ… Notification reader
- âœ… Vision (Screenshot analysis)
- ğŸ”œ Multi-step task planning (Partially implemented via prompts)
- ğŸ”œ Background execution (Service implemented)

---

## ğŸ—ï¸ Architecture

```
phoneclaw/
â”œâ”€â”€ app/                          # Expo Router pages
â”‚   â”œâ”€â”€ (tabs)/
â”‚   â”‚   â”œâ”€â”€ index.tsx             # Home â€” service status & manual controls
â”‚   â”‚   â””â”€â”€ agent.tsx             # Agent chat UI (Phase 2)
â”‚   â””â”€â”€ _layout.tsx
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ native/                   # React Native â†” Kotlin bridge
â”‚   â”‚   â”œâ”€â”€ ClawAccessibilityModule.ts
â”‚   â”‚   â””â”€â”€ ClawAccessibilityService.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                    # Modular tool definitions
â”‚   â”‚   â”œâ”€â”€ index.ts              # Tool registry
â”‚   â”‚   â”œâ”€â”€ touch.ts              # tap, longPress, swipe
â”‚   â”‚   â”œâ”€â”€ navigation.ts         # back, home, recents, scroll
â”‚   â”‚   â”œâ”€â”€ screen.ts             # getScreenText, getUITree
â”‚   â”‚   â”œâ”€â”€ vision.ts             # capture_screen (Phase 3)
â”‚   â”‚   â”œâ”€â”€ notifications.ts      # notification tools (Phase 3)
â”‚   â”‚   â”œâ”€â”€ input.ts              # typeText, clickByText, clickByViewId
â”‚   â”‚   â””â”€â”€ app.ts                # launchApp, getCurrentApp
â”‚   â”‚
â”‚   â””â”€â”€ agent/                    # AI Agent core (Phase 2)
â”‚       â”œâ”€â”€ AgentCore.ts          # LLM reasoning loop
â”‚       â””â”€â”€ prompts.ts            # System prompts & tool definitions
â”‚
â”œâ”€â”€ android/app/src/main/java/com/phoneclaw/app/
â”‚   â”œâ”€â”€ ClawAccessibilityService.kt   # Core service â€” all native actions
â”‚   â”œâ”€â”€ ClawNotificationService.kt    # Notification listener (Phase 3)
â”‚   â”œâ”€â”€ ClawAccessibilityModule.kt    # React Native bridge module
â”‚   â”œâ”€â”€ ClawAccessibilityPackage.kt   # RN package registration
â”‚   â”œâ”€â”€ ClawAccessibilityServiceHolder.kt  # Singleton reference
â”‚   â”œâ”€â”€ MainApplication.kt
â”‚   â””â”€â”€ MainActivity.kt
â”‚
â”œâ”€â”€ android/app/src/main/res/xml/
â”‚   â””â”€â”€ accessibility_service_config.xml  # Service capabilities config
â”‚
â””â”€â”€ plugins/
    â””â”€â”€ with-accessibility-service.js     # Expo config plugin
```

---

## ğŸš€ Getting Started

### Prerequisites
- **Node.js** 18+
- **JDK 17** (not newer â€” JDK 24 breaks the build)
- **Android SDK** with NDK `27.1.12297006`
- Physical Android device with USB debugging enabled

### Setup

```bash
# Clone the repo
git clone https://github.com/yourusername/phoneclaw.git
cd phoneclaw

# Install dependencies
npm install

# Build and run on connected Android device
export JAVA_HOME=$(/usr/libexec/java_home -v 17)
npx expo run:android --device
```

### Enable Accessibility Service

1. Open **Settings** â†’ **Accessibility** â†’ **Installed Services**
2. Find **PhoneClaw** and toggle it **On**
3. Accept the permission prompt
4. Return to the app â€” the status should show âœ… Running

---

## ğŸ› ï¸ Development

```bash
# Run on device (requires native rebuild for Kotlin changes)
export JAVA_HOME=$(/usr/libexec/java_home -v 17)
npx expo run:android --device

# JS-only changes hot-reload automatically via Metro
# Kotlin changes require a full rebuild
```

### Adding a New Tool

1. **Kotlin** â€” Add the method to `ClawAccessibilityService.kt`
2. **Bridge** â€” Add `@ReactMethod` wrapper in `ClawAccessibilityModule.kt`
3. **JS Bridge** â€” Add the native method binding in `ClawAccessibilityModule.ts`
4. **Tool Definition** â€” Register in `src/tools/` with name, description, params

---

## ğŸ“„ License

MIT â€” see [LICENSE](LICENSE) for details.

---

## ğŸ™ Inspiration

- [OpenClaw](https://github.com/open-claw) â€” Personal AI agent with full system access
- Android Accessibility Service documentation
- React Native Native Modules
